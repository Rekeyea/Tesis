\section{Introducción a Big Data y Streaming de Datos}

\subsection{Sistemas Distribuidos}
Un sistema distribuido es una colección de elementos computacionales autónomos que para su usuario 
parecen un sistema único y coherente. \parencite{tanenbaum}

Los sistemas distribuidos tienen dos caracteristicas que pueden regularse para escalar: Procesamiento y Almacenamiento. 
\newline

En el último tiempo, ha habido una tendencia a preferir que la escala de ambas propiedades sea individual. 
Es decir, que se pueda escalar por un lado la potencia de procesamiento y por otro la capacidad de almacenamiento.

\subsubsection{Consistencia}
La Consistencia es la propiedad que tiene un sistema distribuido en la que todos los nodos ven los mismos datos al mismo tiempo.
Esto significa que cualquier lectura en cualquier momento deberá devolver el valor más reciente escrito para ese dato.
Si un sistema es consistente, una vez que se realiza una escritura, todas las lecturas subsiguientes deben reflejar esa escritura;
sin importar desde que nodo se hagan. 
Esta propiedad garantiza que los clientes de los sistemas nunca vean datos desactualizados o inconsistentes.
\newpage
\subsubsection{Disponibilidad}
La Disponibilidad es la propiedad que tiene un sistema distribuido para responder a todas las peticiones, ya sean de lectura o escritura, sin fallos.
Un sistema disponible garantiza que cada solicitud reciba una respuesta sin importar el estado individual de cada nodo que lo compone.
Esto significa que incluso si algunos nodos falla, el sistema en su conjunto debe poder seguir dando servicio a las peticiones que recibe.
\subsubsection{Tolerancia a Particiones}
La Tolerancia a Particiones es la propiedad que tiene un sistema distribuido en la que continua funcionando a pesar de la pérdida de 
conectividad entre nodos. Una partición ocurre cuando hay una ruptura en la comunicación dentro de la red, 
lo que resulta en que dos o más segmentos de la red no puedan comunicarse entre sí.
Un sistema tolerante a particiones puede seguir operando incluso cuando estas particiones ocurren, 
lo que significa que puede manejar retrasos o pérdidas de mensajes entre nodos sin fallar por completo. 

\newpage
\subsection{Definición y características del Big Data}

Big Data es un término que se usa para denominar a un conjunto de tecnologías que manejan grandes volúmenes de datos.
La pregunta que se presenta entonces es: ¿qué tan grandes deberían ser estos volúmenes para ser considerados Big Data?
O incluso, ¿existen otras características que definan lo que es Big Data?
Una definición generalmente aceptada es la siguiente:
\bigskip

Las tecnologías de Big Data están orientadas a
procesar datos de alto volumen, alta velocidad y alta variedad
para extraer el valor de datos previsto y asegurar una alta
veracidad de los datos originales y la información obtenida, lo que demanda
formas de procesamiento de datos e información rentables e innovadoras
para mejorar el conocimiento, la toma de decisiones y el control de procesos. \newline

Todo esto exige nuevos modelos de datos
que soporten todos los estados y etapas de los datos durante todo su ciclo de vida, 
y nuevos servicios y herramientas de infraestructura que permitan obtener y procesar
datos de una variedad de fuentes y
entregar datos en una variedad de formas a diferentes consumidores y dispositivos
de datos e información. \parencite{demchenko2014addressing}

\newpage
Por lo que podríamos considerar que es Big Data todo aquello que esté orientado a datos
cuyo volumen, velocidad y variedad no puedan ser tratados por un modelo de procesamiento
de datos tradicional (como podrían ser las bases de datos relacionales). Con el objetivo
de generar valor, asegurando la veracidad de los datos originales y la información obtenida.

\subsection{Streaming de datos}

El streaming de datos, también conocido como procesamiento de flujo, es un paradigma 
de procesamiento de datos en el que los datos se tratan como un flujo continuo e 
ilimitado de eventos discretos. En el contexto de Big Data, el streaming permite procesar 
y analizar grandes volúmenes de datos en tiempo real o casi real, a medida que se generan 
o llegan al sistema. \parencite{flink}

\subsection{Teorema CAP}
El Teorema CAP es un concepto fundamental en el diseño de sistemas distribuidos. 
Este establece que es imposible garantizar al mismo tiempo, tanto la Consistencia (Consistency), 
Disponibilidad (Availability) y la Tolerancia a las Particiones (Partition Tolerance).\newline

Según esto, un sistema distribuido sólo es capaz de garantizar dos de estas propiedades al mismo tiempo. 
En general, para los sistemas de Big Data de Streaming, la disponibilidad es una propiedad obligatoria, ya que cualquier inactividad puede 
resultar en la pérdida de datos valiosos o en la imposibilidad de realizar acciones.\newline

Por otro lado, la Tolerancia a Particiones es también indispensable para estos sistemas, que por su naturaleza requieren que su capacidad de 
procesamiento este distribuida a través de múltiples nodos dispersos en una red no confiable; por lo que son susceptibles 
a que se genere una partición. Por lo tanto, si no tuviera esta propiedad el servicio podría dejar de ser disponible.\newline 

Entonces, como corolario, un sistema de Big Data de Streaming debe también ser tolerante a las particiones para poder ser disponible.
Esto nos deja con una única opción: relajar el "grado de consistencia" hasta un punto razonable que permita que el sistema siga siendo eficaz.\parencite{capteo}
\newpage
\subsubsection{Consistencia Eventual}
La consistencia eventual es un modelo de consistencia en sistemas distribuidos que garantiza que, 
si no se realizan nuevas actualizaciones a un objeto, en algún momento (eventualmente) todos los accesos a ese objeto 
devolverán el último valor actualizado. \newline

La consistencia eventual se alinea con las compensaciones descritas por el teorema CAP, 
permitiendo que estos sistemas prioricen la disponibilidad y la tolerancia a particiones. \newline

Además, facilita la escalabilidad horizontal, crucial para manejar el crecimiento continuo de datos y clientes de los sistemas.
Por último, es importante diseñar cuidadosamente el sistema para manejar las posibles inconsistencias temporales 
y asegurar que la aplicación pueda tolerar y resolver estas situaciones de manera apropiada \parencite{capteo}

\newpage

\subsection{Principio SCV}

El principio SCV (Speed, Consistency, Volume o Velocidad, Consistencia y Volumen) es como el teorema CAP pero para el procesamiento distribuido. 

Establece que un sistema de procesamiento de datos distribuido solo puede optimizar dos de las siguientes tres dimensiones:

\begin{itemize}
    \item \textbf{Speed}: La rapidez con que se procesan los datos una vez generados; asociada con la latencia
    \item \textbf{Consistency}: La precisión y exactitud de los resultados. Un sistema más consistente utiliza todos los datos disponibles, mientras que uno menos consistente emplea técnicas de muestreo
    \item \textbf{Volume}: La cantidad de datos que pueden procesarse. Los entornos de Big Data generan conjuntos de datos enormes que requieren procesamiento distribuido
\end{itemize}

Las compensaciones entre estas dimensiones son:

\begin{itemize}
    \item Si se necesita velocidad y consistencia, no es posible procesar grandes volúmenes de datos
    \item Si se necesita consistencia y alto volumen, la velocidad de procesamiento se verá comprometida
    \item Si se necesita alto volumen y alta velocidad, los resultados carecerán de consistencia debido al muestreo
\end{itemize}

En entornos de Big Data, donde maximizar la disponibilidad de datos es esencial para análisis profundos como identificación de patrones, 
prescindir del volumen debe considerarse cuidadosamente. \newline

Asumiendo que la pérdida de datos es inaceptable, un sistema de análisis en tiempo real normalmente priorizará \textbf{Velocidad + Volumen} o \textbf{Consistencia + Volumen}, 
dependiendo de si se valora más la rapidez o la precisión de los resultados. \parencite{scv}

\newpage

\subsection{Desafíos en el manejo de datos de streaming}

\begin{enumerate}
    \item \textbf{Procesamiento en tiempo real y baja latencia}
    
    El procesamiento de datos debe ocurrir con un retraso mínimo para proporcionar resultados en tiempo real.
    
    Un desafío clave en el streaming es lograr equilibrar la latencia, el costo y la correctitud simultáneamente \parencite{akidau2015dataflow}.

    \item \textbf{Manejo de datos fuera de orden}
    
    Los datos pueden llegar en un orden diferente al que fueron generados, lo que complica el procesamiento.
    
    El procesamiento de eventos fuera de orden es un desafío fundamental en los sistemas de streaming \parencite[p.~87]{flink}.

    \item \textbf{Escalabilidad}
    
    Los sistemas deben poder manejar volúmenes crecientes de datos sin degradación del rendimiento.
    
    La escalabilidad en sistemas de streaming implica la capacidad de aumentar el rendimiento añadiendo recursos computacionales \parencite{samurai}.

    \newpage
    \item \textbf{Tolerancia a fallos y consistencia}
    
    El sistema debe poder recuperarse de fallos sin pérdida de datos y mantener la consistencia eventual de los resultados.
    
    Garantizar la semántica de "exactly-once" en presencia de fallos es un desafío significativo en streaming \parencite{carbone2015apache}.

    \item \textbf{Procesamiento de ventanas temporales}
    
    Definir y procesar eficientemente ventanas de tiempo sobre streams de datos continuos.
    
    El procesamiento de ventanas temporales es fundamental en aplicaciones de streaming y requiere consideraciones cuidadosas en cuanto a la semántica del tiempo y la completitud de los datos \parencite{akidau2015dataflow}.

    \item \textbf{Integración con sistemas batch}
    
    Combinar eficazmente el streaming con sistemas batch existentes.
    
    La integración de paradigmas batch y streaming, a menudo referida como 'procesamiento híbrido', presenta desafíos únicos en términos de consistencia de datos y modelos de programación \parencite{carbone2015apache}.
\end{enumerate}
\newpage
