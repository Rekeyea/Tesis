\subsection{Almacenamiento de Datos}

\subsubsection {Formatos de Almacenamiento}

Los formatos de datos son un componente fundamental en cualquier arquitectura de sistemas de información moderna, 
ya que determinan no solo cómo se almacena la información, sino también cómo se procesa, transmite y analiza. 
La elección adecuada del formato de datos puede tener un impacto significativo en el rendimiento, 
la escalabilidad y la eficiencia del sistema en su conjunto. Para un sistema de Big Data, 
donde se manejan grandes volúmenes de información, la importancia de estos formatos se magnifica, 
ya que pueden significar la diferencia entre un sistema eficiente y uno que consume recursos excesivos. 
Además, los formatos de datos actúan como un lenguaje común entre diferentes componentes, 
facilitando la interoperabilidad y la integración de tecnologías.

\subsubsection{Formatos Orientados a Filas}
Los formatos orientados a filas representan la forma tradicional de almacenamiento de datos, 
donde cada registro se almacena de manera secuencial. Este enfoque ha sido la base de los sistemas 
de gestión de bases de datos durante décadas y sigue siendo crucial en muchos escenarios.

\begin{itemize}
    \item Los registros completos se almacenan de manera contigua en disco
    \item Cada fila contiene todos los campos de un registro
    \item Optimizado para acceder a registros completos
    \item Los nuevos registros se añaden secuencialmente de forma eficiente
    \item Óptimo cuando las consultan necesitan todos los campos
    \item Fácil modificación de registros individuales
    \item Debe leer datos innecesarios cuando solo se necesitan algunas columnas
    \item Los datos heterogéneos juntos reducen la efectividad de los métodos de compresión
    \item Menos eficiente para análisis de columnas específicas
\end{itemize}

\subsubsection{Formatos Orientados a Columnas}

Los formatos de almacenamiento columnar representan un paradigma fundamental en el manejo de datos masivos, 
especialmente en entornos analíticos. A diferencia del almacenamiento tradicional orientado a filas, 
donde los registros se almacenan secuencialmente, el almacenamiento columnar organiza los datos por columnas, 
lo que ofrece ventajas significativas en ciertos escenarios.

\begin{itemize}
    \item En lugar de almacenar registros completos de manera contigua, los datos se organizan por columnas
    \item Cada columna se almacena en bloques separados de memoria o disco
    \item Los valores similares se almacenan juntos, mejorando la compresión
    \item Los datos similares almacenados juntos permiten mayores tasas de compresión
    \item Solo se leen las columnas necesarias para una consulta
    \item Facilita operaciones como SUM, AVG, COUNT sobre columnas específicas
    \item Permite procesamiento eficiente de datos en hardware
\end{itemize}

\subsubsection{Comparativa con Almacenamiento por Filas:}

Consideremos una tabla simple de usuarios:

\textbf{Formato por Filas:}
\begin{verbatim}
[ID1, "Juan", 25] -> [ID2, "Ana", 30] -> [ID3, "Pedro", 28]
\end{verbatim}

\textbf{Formato Columnar:}
\begin{verbatim}
IDs:    [ID1 -> ID2 -> ID3]
Nombres: ["Juan" -> "Ana" -> "Pedro"]
Edades:  [25 -> 30 -> 28]
\end{verbatim}

\begin{tabular}{|l|l|l|}
\hline
\textbf{Aspecto} & \textbf{Formato Columnar} & \textbf{Formato por Filas} \\
\hline
Lectura parcial & Muy eficiente & Menos eficiente \\
Inserción de registros & Más lenta & Más rápida \\
Compresión & Alta & Moderada \\
Consultas analíticas & Excelente & Regular \\
Consultas transaccionales & Regular & Excelente \\
\hline
\end{tabular}

\subsubsection{Formatos Específicos}

\paragraph{JSON (JavaScript Object Notation)} 
se ha convertido en el estándar de facto para el intercambio 
de datos en aplicaciones modernas, especialmente en entornos Web y APIs. Su popularidad se debe a su 
simplicidad, legibilidad humana y amplia compatibilidad con prácticamente todos los lenguajes de 
programación. A pesar de no ser el más eficiente en términos de espacio y rendimiento (ya que es un formato basado en filas), 
su flexibilidad para representar datos estructurados y semiestructurados lo hace invaluable en sistemas donde la 
interoperabilidad y la facilidad de desarrollo son prioritarias. Es particularmente útil en aplicaciones
donde las transacciones individuales y la flexibilidad del esquema son más importantes que la 
eficiencia en el procesamiento de grandes volúmenes de datos.

\paragraph{Apache AVRO} 
destaca como un formato de serialización de datos binario que combina la 
eficiencia del almacenamiento binario con la flexibilidad de esquemas evolutivos. Su característica 
más distintiva es su capacidad para manejar cambios en el esquema de datos a lo largo del tiempo sin 
requerir cambios en el código o reescritura de datos existentes. Para esto, AVRO almacena el esquema junto con 
los datos, lo que permite una deserialización precisa y eficiente. Es especialmente valioso en 
sistemas de mensajería y streaming de datos, donde la evolución del esquema y la 
eficiencia en la transmisión son cruciales. Su formato binario compacto y su capacidad de compresión 
lo hacen ideal para sistemas distribuidos donde el ancho de banda y el almacenamiento son 
consideraciones importantes.

\paragraph{Apache Parquet} 
se ha establecido como el formato columnar dominante en el ecosistema de 
Big Data, especialmente para cargas de trabajo analíticas. Su diseño columnar permite una compresión 
altamente eficiente y un muy buen rendimiento en consultas que involucran solo un subconjunto de 
columnas. Parquet destaca particularmente en escenarios de análisis de datos, 
donde su capacidad para manejar esquemas complejos anidados y su integración con 
casi todas las herramientas lo hacen indispensable. La adopción generalizada de Parquet en la 
industria, lo ha convertido en el estándar de facto para almacenamiento de datos analíticos.

\newpage
\paragraph{Optimized Row Columnar (ORC)} 
inicialmente fué desarrollado para optimizar Hive, 
y aunque ofrece excelentes capacidades de compresión y rendimiento en consultas, su relevancia 
ha disminuido significativamente en los últimos años frente a Parquet. Aunque ORC sigue siendo 
relevante en sistemas legacy y específicos de Hive, la tendencia de la industria se ha movido 
claramente hacia Parquet como el formato columnar preferido para análisis de datos a gran escala.

\subsubsection{Almacenamiento de Objetos en la Nube}

El almacenamiento de objetos en la nube constituye un paradigma de almacenamiento donde los datos se organizan y gestionan como objetos independientes dentro de una estructura plana.
Cada objeto almacenado comprende tres elementos fundamentales: los datos en sí mismos, un conjunto extenso de metadatos que describen y categorizan la información, 
y un identificador único global que permite su localización y recuperación. 
Dicho paradigma, se caracteriza por su naturaleza distribuida y su capacidad para manejar tanto datos estructurados como no estructurados, 
permitiendo almacenar desde documentos, archivos multimedia y hasta flujos de datos en tiempo real.

Los sistemas de almacenamiento de objetos se destaca por su capacidad para satisfacer las demandas contemporáneas de procesamiento de datos a gran escala.
Como por ejemplo, ofrece una escalabilidad prácticamente ilimitada, pudiendo crecer según las necesidades sin preocuparse por restricciones de capacidad.
Por otro lado, la durabilidad y disponibilidad de los datos se garantiza a través de la replicación automática en múltiples ubicaciones de forma automática y transparente.
Adicionalmente, proveen APIs normalmente basadas en el protocolo HTTP que permite acceder de forma interoperable y estandarizada a los recursos almacenados

El uso de estos sistemas tambien conlleva sus propios desafíos. El más importante puede ser la latencia; pero también deben los grados de consistencia que ofrecen.

\clearpage
\subsubsection{Bases de Datos Analíticas}

Las bases de datos analíticas, también conocidas como bases de datos OLAP (Online Analytical Processing) orientadas a tiempo real, 
son sistemas especializados diseñados para procesar y analizar grandes volúmenes de datos con énfasis particular en consultas complejas y agregaciones. 
Estos sistemas están arquitecturalmente optimizados para procesar rápidamente consultas que involucran múltiples dimensiones y métricas sobre conjuntos masivos de datos, 
permitiendo análisis en tiempo real o casi real. 

Estas bases de datos se distinguen por su capacidad de manejar cargas de trabajo analíticas complejas mientras mantienen latencias bajas y consistentes; 
especializandose en resultados en segundos o milisegundos.Esta característica se debe a su arquitectura orientada específicamente al análisis, 
que contrasta con los sistemas diseñados primariamente para transacciones (OLTP) o almacenamiento general de datos.

Por diseño permiten un análisis multidimensional eficiente, soportan alta concurrencia de usuarios, y pueden integrarse efectivamente con fuentes de datos en streaming.
Además, su diseño orientado a columnas permite una compresión más eficiente y mejor rendimiento en consultas analíticas que típicamente involucran solo un subconjunto de ellas. 
Proporcionando capacidades avanzadas de agregación y pueden manejar eficientemente tanto datos históricos como en tiempo real.

Ninguno de estos beneficios vienen sin sus propios desafios, ya que se requiere una cuidadosa planificacion, operación y mantenimiento para ,amtemer su rendimiento.
Además, más que nunca, es necesario organizar correctamente los indices y los esquemas de particionamiento son claves.

Ejemplos de estos sistemas son:

\paragraph{Apache Druid}
es una base de datos analítica distribuida diseñada principalmente para análisis en tiempo real de grandes volúmenes de datos de series temporales. 
Su arquitectura se distingue por su capacidad de ingesta en tiempo real combinada con consultas de baja latencia, 
utilizando un modelo de almacenamiento columnar híbrido que combina datos en memoria con almacenamiento en disco. 

\paragraph{Apache Pinot} 
fué desarrollado incialmente por LinkedIn y se enfoca en proporcionar análisis en tiempo real con latencias extremadamente bajas, 
incluso en escenarios de alta concurrencia de usuarios. 
Su arquitectura está optimizada para consultas de lectura masivas y paralelas. 
Además, destaca por su modelo de consistencia eventual y su capacidad para manejar esquemas dinámicos.

\paragraph{Apache Doris} 
inicialmente fue desarrollado por Baidu, integra capacidades de almacenamiento columnar MPP (Procesamiento Paralelo Masivo) con funcionalidades OLAP, 
ofreciendo una solución más cercana a una base de datos tradicional pero con capacidades analíticas avanzadas. 
Su arquitectura es más simple en comparación con Druid y Pinot, lo que facilita la operación y mantenimiento, manteniendo un buen rendimiento para consultas analíticas.

\newpage