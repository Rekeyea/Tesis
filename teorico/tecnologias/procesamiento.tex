\subsection{Motores de Procesamiento}

Si las tecnologías de mensajería distribuida son el sistema nervioso de un sistema de Big Data de Streaming, 
los motores de procesamiento podrían considerarse su cerebro.

Actúan como la capa que transforma, enriquece y analiza los datos cumpliendo varios roles:
\begin{itemize}
    \item Aplicar la lógica de negocio sobre los datos mientras estos fluyen
    \item Detectar patrones y anomalías sobre el flujo de datos
    \item Mantener el contexto y estado necesario para las operaciones con históricos o agregaciones
    \item Garantizar la consistencia de las operaciones incluso ante fallos del sistema
    \item Distribuir la carga de trabajo entre diferentes nodos, paralelizando tareas
\end{itemize}

Estos componentes pueden enlazarse y programarse de diversas maneras. Permitiendo ensamblarlos de forma de cumplir 
con los requisitos de negocio.

\subsubsection{Apache Spark}

Apache Spark se destaca como uno de los motores de procesamiento más populares y versátiles en el ecosistema de Big Data.
Ofrece dos APIs principales para el procesamiento en tiempo real: Spark Streaming y Structured Streaming,
siendo esta última la más moderna y recomendada. Implementa el procesamiento en tiempo real tratando los datos streaming
como micro-batches y su enfoque de procesamiento es en memoria, siendo capaz de mantener su estado distribuido a través
de checkpoints, que son archivos que se guardan en un sistema de almacenamiento al que todos los nodos pueden acceder.
Su modelo de procesamiento le permite ofrecer un cierto equilibrio entre latencia y throughput. La abstracción fundamental
de Spark son los RDDs (Resilient Distributed Datasets), que son colecciones inmutables de datos distribuidos que pueden
ser procesadas en paralelo, y los DataFrames, que proporcionan una abstracción de más alto nivel similar a una tabla de
base de datos.
Spark destaca por su amplio soporte de lenguajes de programación:

\begin{itemize}
    \item Scala
    \item Python
    \item Java 
    \item R
    \item SQL
\end{itemize}

Su API unificada y extenso catálogo de bibliotecas incluye MLlib para machine learning, GraphX para procesamiento de
grafos, y Spark SQL para procesamiento estructurado.

\subsubsection{Apache Flink}

Apache Flink adopta un enfoque nativo de streaming, tratando al procesamiento batch como un caso especial de streaming
con límites finitos. Su arquitectura está diseñada para mantener estado distribuido con garantías de consistencia muy
fuertes y latencias extremadamente bajas. El motor gestiona automáticamente la distribución del estado y los checkpoints,
asegurando semánticas de exactly-once y permitiendo recuperación exacta ante fallos sin duplicados.
Su modelo de procesamiento se basa en dos conceptos fundamentales:

\begin{itemize}
    \item Marcas de agua (Watermarks): Son metadatos que fluyen en el stream de datos indicando el progreso del tiempo del evento,
    permitiendo manejar datos desordenados.
    \item Ventanas de tiempo (Windows): Permiten agrupar y procesar datos en intervalos temporales definidos, soportando diversos
    tipos como tumbling, sliding y session windows. 
\end{itemize}

Flink proporciona APIs de diferentes niveles:

\begin{itemize}
    \item ProcessFunction: API de bajo nivel que ofrece máximo control sobre tiempo, estado y ventanas
    \item DataStream API: API de alto nivel para operaciones de streaming comunes
    \item Table API y SQL: APIs declarativas para operaciones relacionales   
\end{itemize}

Los lenguajes soportados son:

\begin{itemize}
    \item Java
    \item Scala
    \item Python
    \item SQL
\end{itemize}

\subsubsection{Apache Beam}

Apache Beam, por su lado, se distingue por proporcionar un modelo de programación unificado que abstrae el motor de ejecución subyacente.
Su potencia radica en la capacidad de escribir la lógica de procesamiento una vez y ejecutarla en 
diferentes motores de procesamiento (runners) como Spark o Flink.
Esta capacidad de abstracción es particularmente valiosa en escenarios donde la portabilidad y la flexibilidad de despliegue son requisitos clave, 
permitiendo cambiar de motor de procesamiento según evolucionen las necesidades y sin reescribir el código de procesamiento.

\subsubsection{Apache Samza}

Apache Samza se distingue por su estrecha integración con Apache Kafka y su arquitectura diseñada para mantener el estado 
de procesamiento de forma distribuida con un modelo de particionamiento que permite escalar horizontalmente.
Samza proporciona un modelo de procesamiento simple pero potente, con fuerte énfasis en la gestión de estado local y la tolerancia a fallos.
Se utiliza en Linkedin y la arquitectura Kappa fué propuesta inicialmente pensando en la utilización de este motor de procesamiento.

\subsubsection{Apache NiFi}

Apache NiFi aborda el procesamiento de datos desde una perspectiva de orquestación y gobierno de datos; 
centrándose en la automatización del flujo de datos entre sistemas.
Su arquitectura está orientada a la trazabilidad y auditabilidad de cada dato que fluye por el sistema, 
manteniendo un registro detallado de todas las transformaciones y movimientos. Los datos fluyen 
a través de un grafo de procesadores que pueden transformar, enrutar y mediar entre diferentes protocolos y formatos. 
NiFi se destaca por su capacidad para garantizar la entrega confiable de datos, proveer linaje de datos completo y 
permitir modificaciones de flujos en tiempo real sin necesidad de detener el sistema.
Por último, NiFi proporciona una interfaz visual para diseñar, controlar y 
monitorizar flujos de datos.

\subsubsection{Apache Kafka Streams}

Apache Kafka Streams es una biblioteca de procesamiento de streaming que forma parte del ecosistema de Apache Kafka, diseñada para construir aplicaciones y microservicios de procesamiento en tiempo real.
Opera con un modelo de procesamiento que permite operaciones con manejo de estado, incluyendo agregaciones por ventanas, manejo de múltiples streams de datos 
y transformaciones complejas mediante APIs de alto y bajo nivel. Tiene un manejo de estado distribuido que se gestionan con los mismos logs de Kafka.
En cuanto a rendimiento, Kafka Streams alcanza una latencia típica de decenas de milisegundos a segundos, dependiendo de la complejidad del procesamiento y la configuración, 
mientras que su throughput puede escalar linealmente añadiendo más instancias. También cfrece grantías de procesamiento at-least-once con posibilidad de exactly-once mediante configuración.


\subsubsection{Apache Pulsar Functions}

Apache Pulsar Functions ofrece capacidad de cómputo integrandose directamente en la infraestructura de Apache Pulsar. 
Este framework permite implementar funciones livianas que procesan mensaje a mensaje. 
El manejo del estado es distribuido y se realiza mediante un almacenamiento basado en RocksDB, que permite mantener información 
entre invocaciones de funciones de manera consistente y tolerante a fallos. En términos de rendimiento, está optimizado para baja latencia, típicamente en el rango de milisegundos, 
gracias a su modelo de procesamiento directo. 
El throughput puede escalar horizontalmente añadiendo más instancias de funciones, y el sistema proporciona garantías de procesamiento exactly-once 
La arquitectura de este sistema está diseñada para ser simple y eficiente, permitiendo casos de uso como enriquecimiento de datos, filtrado, y transformaciones 
en tiempo real.


\subsubsection{Comparación}

\setlength\cellspacetoplimit{4pt}
\setlength\cellspacebottomlimit{4pt}

\begin{table}[htbp]
    \footnotesize
    \renewcommand{\arraystretch}{1.2}
    \centering
    \caption{Comparativa de Motores de Procesamiento Big Data}
    \label{tab:comparison-engines}
    \setlength{\tabcolsep}{3pt}
    \begin{tabularx}{\textwidth}{|>{\raggedright\arraybackslash}m{2.2cm}|>{\raggedright\arraybackslash}m{0.14\textwidth}|>{\raggedright\arraybackslash}m{0.16\textwidth}|>{\raggedright\arraybackslash}m{0.14\textwidth}|>{\raggedright\arraybackslash}m{0.16\textwidth}|>{\raggedright\arraybackslash}m{0.14\textwidth}|}
    \hline
    \rule{0pt}{5ex} & \textbf{Modelo} & \textbf{Estado} & \textbf{Latencia} & \textbf{Throughput} & \textbf{Garantías} \\[0.3ex]
    \hline
    \textbf{Apache Spark} & Micro-batches & En memoria & Media & Muy alto & At-least-once \\[0.3ex]
    \hline
    \textbf{Apache Flink} & Streaming & Distribuido & Muy baja & Alto & Exactly-once \\[0.3ex]
    \hline
    \textbf{Apache Beam} & Modelo unificado & Según runner & Variable & Variable & Según runner \\[0.3ex]
    \hline
    \textbf{Apache Samza} & Streaming & Local por partición & Baja & Alto & At-least-once \\[0.3ex]
    \hline
    \textbf{Apache NiFi} & Flujo dirigido & Local por procesador & Media-Alta & Medio & At-least-once \\[0.3ex]
    \hline
    \textbf{Kafka Streams} & Streaming & Distribuido & Baja & Alto & Exactly-once \\[0.3ex]
    \hline
    \textbf{Pulsar Funcitons} & Mensaje & Distribuido & Muy Baja & Alto & Exactly-once \\[0.3ex]
    \hline
    \end{tabularx}
    \end{table}